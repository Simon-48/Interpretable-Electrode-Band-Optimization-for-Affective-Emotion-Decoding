#  Interpretable Electrode-Band Optimization for Affective Emotion Decoding.

This project aims to perform emotion recognition using the DEAP dataset, which contains EEG recordings from 32 participants across 40 electrodes. The objective is to predict four emotional dimensions: arousal (intensity of emotion or alertness), valence (pleasantness of the emotion), dominance (control or influence over the emotion), and liking (subjective preference or enjoyment).

Initially, the Fast Fourier Transform (FFT) was applied to convert raw EEG signals from the time domain to the frequency domain. This transformation allowed for the structuring of the data in a tabular format with five frequency bands per electrode, enabling compatibility with conventional machine learning and deep learning techniques.

While traditional sequential models like LSTM and RNN struggled to deliver satisfactory results on raw time-series EEG data, a customized Residual Convolutional Neural Network (CNN) was later developed. This CNN architecture outperformed both classical machine learning and deep learning baselines in terms of prediction accuracy, robustness, and generalization across the four emotional dimensions.

To enhance model interpretability and reduce computational burden, SHapley Additive exPlanations (SHAP) analysis was applied. SHAP identified the most informative electrodes and associated frequency bands contributing to emotion decoding. Remarkably, training the CNN using only this optimized set of electrodes and bands resulted in nearly identical performance compared to the full model (over 98% of the original model's performance), while substantially reducing the number of input features, training time, and model complexity.

To evaluate the cross-dataset generalization of the optimized model, the selected electrode-frequency set was mapped to the SEED-V and AMIGO datasets. The performance on both datasets closely matched that of full-feature models, demonstrating strong consistency and transferability. Specifically, the optimized configuration retained over 96% of the original model's performance for SEED-V and over 98% for AMIGO, while significantly reducing the number of electrodes and input features. These results underscore the modelâ€™s scalability and the physiological relevance of the selected brain regions, particularly the fronto-central and parieto-occipital areas, in emotional decoding across diverse datasets.

**The notebook EEG_Conversion contains the conversion of raw EEG data from the time domain to the frequency domain. The Brain_models notebook includes the implementation of various models trained on the full dataset for binary classification.**

**The notebook Brain-XAI-Updated contains the ideal set of electrodes. Based on this, the optimal electrodes were utilized in the IDEAL_EEG notebook for binary classification tasks and in the IDEAL_EEG_Multiclass notebook for multiclass prediction tasks. All the above analyses are done based on person-dependent data, where the data is separated based on videos rather than individuals. Therefore, the same person's data may appear in both the training and testing sets, differentiated by the videos.** 

**Additionally, in the Models_PersonIndependent notebook for binary classification and the PersonIndependent_IDEAL_EEG_Multiclass notebook for multiclass classification, the optimal set of electrodes is used for person-independent analysis, where the training and testing data consist of a mixture of data from different individuals. The conversion for person-independent analysis is provided in the EEG_PersonIndependent notebook.** 
